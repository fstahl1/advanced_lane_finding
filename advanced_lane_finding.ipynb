{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project specification\n",
    "\n",
    "\n",
    "## 1) Calibration (camera matrix, distortion coefficients)\n",
    "\n",
    "## Pipeline\n",
    "* 2) Color transform, Gradients -> thresholded binary image\n",
    "* 3) Perspective transform\n",
    "* 4) Identification of lane line pixels\n",
    "* 5) Radius of curvature calculation\n",
    "* 6) Lane area plotted back down onto the road\n",
    "\n",
    "* (7) Lane history + smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Calibration\n",
    "\n",
    "\n",
    "Theory\n",
    "\n",
    "### todo: _intrinsic or extrinsic?!_ -> distortion correction\n",
    "\n",
    "\"For better results, we need atleast 10 test patterns.\"\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "\n",
    "\"Now for X,Y values, we can simply pass the points as (0,0), (1,0), (2,0), ... which denotes the location of points. In this case, the results we get will be in the scale of size of chess board square.\" https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "\n",
    "...\n",
    "\n",
    "---\n",
    "\n",
    "* a) Prepare object points for chessboard corners\n",
    "* b) Find chessboard corners in all images\n",
    "* c) Calibrate camera (distortion correction) https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "* d) get perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from help_func import plot, draw_lines_from_points\n",
    "import pickle\n",
    "# for interactive plots\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moved to calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize array for object points with dimensions (6*9, 3)\n",
    "# objp = np.zeros((6*9,3), np.float32)\n",
    "# # create mesh grid, transpose and reshape to get an (6*9, 2) array \n",
    "# # for all object points (z component is assumed to be 0)\n",
    "# objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# # initialize arrays for object- and image points from all\n",
    "# # calibration images\n",
    "# objpts = [] # 3D points in real world space\n",
    "# imgpts = [] # 2D points in image plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moved to calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get list of all available calibration images\n",
    "# cal_images = glob.glob('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moved to calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find chessboard corners in all images\n",
    "# for idx, img_name in enumerate(cal_images):\n",
    "#     img = cv2.imread(img_name) # read image\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "    \n",
    "#     # find chessboard corners\n",
    "#     ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "    \n",
    "#     # if corners were found, object- and image points are added\n",
    "#     if ret == True:\n",
    "#         objpts.append(objp)\n",
    "#         imgpts.append(corners)\n",
    "\n",
    "#         # draw and display/save corners\n",
    "# #         cv2.drawChessboardCorners(img, (9,6), corners, ret)        \n",
    "# #         folder_name = 'output_images/'\n",
    "# #        # file_name = 'chessboard_corners_'+img_name[11:]\n",
    "# #        # cv2.imwrite(folder_name+file_name, img)\n",
    "#         # cv2.imshow('img', img)\n",
    "#         # cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea for calibration function:\n",
    "https://github.com/mithi/advanced-lane-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo: class and functions descriptions\n",
    "class Calibration:\n",
    "    \n",
    "    def __init__(self, cam_mtx, dist_coeff, src_pts, dst_pts):\n",
    "        self.cam_mtx = cam_mtx\n",
    "        self.dist_coeff = dist_coeff\n",
    "        self.src_pts = src_pts\n",
    "        self.dst_pts = dst_pts\n",
    "        self.warp_mtx = cv2.get_PerspectiveTransform(scr_pts, dst_pts)\n",
    "        \n",
    "    def undistort(self, dist_img):\n",
    "        undist_img = cv2.undistort(dist_img, self.cam_mtx, \n",
    "                                   self.dist_coeff, None, \n",
    "                                   self.cam_mtx)\n",
    "        return undist_img\n",
    "    \n",
    "    def warp(self, img):\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        warped_img = cv2.warpPerspective(img, self.warp_mtx, \n",
    "                                         img_size, \n",
    "                                         flags = cv2.INTER_LINEAR)\n",
    "        return warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moved to calibration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # load distorted image and get size\n",
    "# dist_img = cv2.imread('camera_cal/calibration2.jpg')\n",
    "# img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# # calibrate camera (returns the camera matrix, distortion coefficients, rotation and translation vectors)\n",
    "# ret, mtx, dist_coeff, rvecs, tvecs = cv2.calibrateCamera(objpts, imgpts, img_size, None ,None)\n",
    "\n",
    "# calib = Calibration(mtx, dist_coeff, src_pts, dst_pts)\n",
    "\n",
    "# undist_img = calib.undistort(dist_img)\n",
    "\n",
    "# # undistort example image\n",
    "# # undist = cv2.undistort(dist_img, mtx, dist_coeff, None, mtx)\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# f.tight_layout()\n",
    "\n",
    "# ax1.imshow(dist_img)\n",
    "# ax2.imshow(undist_img)\n",
    "\n",
    "# # plt.imshow(undist_img)\n",
    "# # cv2.imwrite('output_images/calibration2_undistorted.jpg', undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_data = pickle.load(open(\"pickled_calib_data.p\", \"rb\"))\n",
    "mtx = pickled_data[\"mtx\"]\n",
    "dist_coeff = pickled_data[\"dist_coeff\"]\n",
    "warp_mtx = pickled_data[\"warp_mtx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create binary image\n",
    "\n",
    "### gradient (function sobel_thresh)\n",
    "\n",
    ">\"In our last example, output datatype is cv2.CV_8U or np.uint8. But there is a slight problem with that. Black-to-White transition is taken as Positive slope (it has a positive value) while White-to-Black transition is taken as a Negative slope (It has negative value). So when you convert data to np.uint8, all negative slopes are made zero. In simple words, you miss that edge.\n",
    "\n",
    ">If you want to detect both edges, better option is to keep the output datatype to some higher forms, like cv2.CV_16S, cv2.CV_64F etc, take its absolute value and then convert back to cv2.CV_8U. Below code demonstrates this procedure for a horizontal Sobel filter and difference in results.\"\n",
    "\n",
    "https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_thresh(img, orient='x', kernel=3, sobel_thresh=(0, 255)):\n",
    "    \"\"\"Creates thresholded binary image based on directional \n",
    "    gradient\"\"\"\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # take derivative in 'orient' direction\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel)\n",
    "    else:\n",
    "        print('only x and y are accepted as 2nd argument')\n",
    "        return None\n",
    "    # calculate absolute value and scale to 8-bit\n",
    "    abs_sobel = np.abs(sobel)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel/np.max(abs_sobel))\n",
    "    # create binary image\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & \n",
    "                scaled_sobel <= thresh[1]] = 1\n",
    "    # return binary image\n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "# img_size = (src_img.shape[1], src_img.shape[0])\n",
    "\n",
    "# undist_img = calib.undistort(src_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_pts determined manually based on the test image straight_lines1.jpg\n",
    "# src_pts = np.array([[560, 475], \n",
    "#                     [725, 475], \n",
    "#                     [1100, img_size[1]], \n",
    "#                     [200, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))\n",
    "# currently chosen:\n",
    "# src_pts = np.array([[580, 460], \n",
    "#                     [700, 460], \n",
    "#                     [1100, img_size[1]], \n",
    "#                     [200, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))\n",
    "# src_pts = np.array([[595, 450], \n",
    "#                     [685, 450], \n",
    "#                     [1100, img_size[1]], \n",
    "#                     [200, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # destination points for perspective transformation\n",
    "# lane_dist = 700 # in pixels\n",
    "# mid_pnt = img_size[0]//2\n",
    "# print(mid_pnt)\n",
    "# # dst_pts = [(mid_pnt - lane_dist, 0), (mid_pnt + lane_dist, 0), \n",
    "# #           (mid_pnt + lane_dist, img_size[1]), \n",
    "# #            (mid_pnt - lane_dist, img_size[0])]\n",
    "# dst_pts = np.array([[mid_pnt - lane_dist/2, 0], \n",
    "#                     [mid_pnt + lane_dist/2, 0], \n",
    "#                     [mid_pnt + lane_dist/2, img_size[1]],\n",
    "#                     [mid_pnt - lane_dist/2, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line1 = np.array([src_pts[0,:], src_pts[1,:]]).reshape(1, 4)\n",
    "# line2 = np.array([src_pts[1,:], src_pts[2,:]]).reshape(1, 4)\n",
    "# line3 = np.array([src_pts[2,:], src_pts[3,:]]).reshape(1, 4)\n",
    "# line4 = np.array([src_pts[3,:], src_pts[0,:]]).reshape(1, 4)\n",
    "# lines = np.vstack([line1, line2, line3, line4]).reshape((4,1,4))\n",
    "# # print(lines.shape)\n",
    "# undist_img_cp = np.copy(undist_img)\n",
    "# draw_lines(undist_img_cp, lines)\n",
    "# plot(undist_img_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwarped_img = np.copy(undist_img)\n",
    "raw_img = mpimg.imread('test_images/test6.jpg')\n",
    "undist_img = calib.undistort(raw_img)\n",
    "# raw_img = mpimg.imread('test_images/test1.jpg')\n",
    "# undist_img = calib.undistort(raw_img)\n",
    "\n",
    "warp_mtx = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warped_img = cv2.warpPerspective(undist_img, warp_mtx, \n",
    "                                 img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(undist_img)\n",
    "line_img1 = draw_lines_from_points(undist_img, src_pts)\n",
    "plt.figure()\n",
    "plt.imshow(undist_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(warped_img)\n",
    "line_img2 = draw_lines_from_points(warped_img, dst_pts)\n",
    "plt.figure()\n",
    "plt.imshow(warped_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(src_img):\n",
    "    # undistort image    \n",
    "    \n",
    "    undist_img = calib.undistort(src_img)\n",
    "#     plot_func(img); plot_func(undist)\n",
    "\n",
    "#     warped_img = calib.warp(undist)\n",
    "    warp_mtx = cv2.getPerspectiveTransform(src_pts, )\n",
    "\n",
    "    plot(undist_img)\n",
    "    plot(warped_img)\n",
    "    \n",
    "    #     grad_thresh(undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "pipeline(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
