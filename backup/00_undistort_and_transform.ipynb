{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from help_func import plot, draw_lines_from_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undistort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize array for object points with dimensions (6*9, 3)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "# create mesh grid, transpose and reshape to get an (6*9, 2) array \n",
    "# for all object points (z component is assumed to be 0)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# initialize arrays for object- and image points from all\n",
    "# calibration images\n",
    "objpts = [] # 3D points in real world space\n",
    "imgpts = [] # 2D points in image plane\n",
    "\n",
    "# get list of all available calibration images\n",
    "cal_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# find chessboard corners in all images\n",
    "for idx, img_name in enumerate(cal_images):\n",
    "    img = cv2.imread(img_name) # read image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "    \n",
    "    # find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "    \n",
    "    # if corners were found, object- and image points are added\n",
    "    if ret == True:\n",
    "        objpts.append(objp)\n",
    "        imgpts.append(corners)\n",
    "\n",
    "        # draw and display/save corners\n",
    "#         cv2.drawChessboardCorners(img, (9,6), corners, ret)        \n",
    "#         folder_name = 'output_images/'\n",
    "#        # file_name = 'chessboard_corners_'+img_name[11:]\n",
    "#        # cv2.imwrite(folder_name+file_name, img)\n",
    "        # cv2.imshow('img', img)\n",
    "        # cv2.waitKey(500)\n",
    "\n",
    "# load distorted image and get size\n",
    "dist_img = cv2.imread('camera_cal/calibration2.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# calibrate camera (returns the camera matrix, distortion \n",
    "# coefficients, rotation and translation vectors)\n",
    "ret, mtx, dist_coeff, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    objpts, imgpts, img_size, None ,None)\n",
    "\n",
    "undist_img = cv2.undistort(dist_img, mtx, dist_coeff)\n",
    "\n",
    "# undistort example image\n",
    "# undist = cv2.undistort(dist_img, mtx, dist_coeff, None, mtx)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(dist_img)\n",
    "ax2.imshow(undist_img)\n",
    "\n",
    "# plt.imshow(undist_img)\n",
    "# cv2.imwrite('output_images/calibration2_undistorted.jpg', undist)\n",
    "\n",
    "\n",
    "\n",
    "# Perspective transform\n",
    "\n",
    "raw_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "img_size = (raw_img.shape[1], raw_img.shape[0])\n",
    "\n",
    "undist_img = cv2.undistort(raw_img, mtx, dist_coeff)\n",
    "\n",
    "# for zooming in\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.imshow(undist_img)\n",
    "plt.title('Undistorted image')\n",
    "\n",
    "# source points manually determined from test image \n",
    "# \"straight_lines1.jpg\"\n",
    "src_pts = np.array([[580, 460], \n",
    "                    [700, 460], \n",
    "                    [1100, img_size[1]], \n",
    "                    [200, img_size[1]]],\n",
    "                   np.float32).reshape((4, 1, 2))\n",
    "\n",
    "# src_pts = np.array([[560, 475], \n",
    "#                     [725, 475], \n",
    "#                     [1100, img_size[1]], \n",
    "#                     [200, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))\n",
    "\n",
    "# src_pts = np.array([[595, 450], \n",
    "#                     [685, 450], \n",
    "#                     [1100, img_size[1]], \n",
    "#                     [200, img_size[1]]], \n",
    "#                    np.float32).reshape((4, 1, 2))\n",
    "\n",
    "# destination points for perspective transformation\n",
    "lane_dist = 700 # in pixels\n",
    "mid_pnt = img_size[0]//2\n",
    "dst_pts = np.array([[mid_pnt - lane_dist/2, 0], \n",
    "                    [mid_pnt + lane_dist/2, 0], \n",
    "                    [mid_pnt + lane_dist/2, img_size[1]],\n",
    "                    [mid_pnt - lane_dist/2, img_size[1]]], \n",
    "                   np.float32).reshape((4, 1, 2))\n",
    "\n",
    "undist_img_cp = np.copy(undist_img)\n",
    "draw_lines_from_points(undist_img_cp, src_pts)\n",
    "plot(undist_img_cp)\n",
    "\n",
    "# perspective transform\n",
    "warp_mtx = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warped_img = cv2.warpPerspective(undist_img, M, \n",
    "                                 img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "draw_lines_from_points(warped_img, dst_pts)\n",
    "plot(warped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\"mtx\": mtx, \"dist_coeff\": dist_coeff, \"warp_mtx\": warp_mtx}, open(\"pickled_calib_data.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
